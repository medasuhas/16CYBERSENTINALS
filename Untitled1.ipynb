{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7a08750",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import re\n",
    "\n",
    "HEADERS = {\"User-Agent\": \"Mozilla/5.0\"}\n",
    "\n",
    "def yahoo_search(query, num_results=10):\n",
    "    search_url = f\"https://search.yahoo.com/search?p={query}\"\n",
    "    try:\n",
    "        response = requests.get(search_url, headers=HEADERS, timeout=5)\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        results = []\n",
    "\n",
    "        for a in soup.select(\"a[href^='http']\"):\n",
    "            href = a['href']\n",
    "            if any(domain in href for domain in ['moneycontrol.com', 'reuters.com', 'livemint.com', 'cnbc.com', 'economictimes.indiatimes.com']):\n",
    "                if href not in results:\n",
    "                    results.append(href)\n",
    "            if len(results) >= num_results:\n",
    "                break\n",
    "        return results\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Yahoo Search failed: {e}\")\n",
    "        return []\n",
    "\n",
    "def extract_bullet_points(content, keywords):\n",
    "    bullets = []\n",
    "    sentences = re.split(r'\\.|\\?|!', content)\n",
    "    for sentence in sentences:\n",
    "        if all(k.lower() in sentence.lower() for k in keywords):\n",
    "            bullets.append(\"â€¢ \" + sentence.strip())\n",
    "    if not bullets:\n",
    "        for sentence in sentences:\n",
    "            if any(k.lower() in sentence.lower() for k in keywords):\n",
    "                bullets.append(\"â€¢ \" + sentence.strip())\n",
    "    return bullets[:3]\n",
    "\n",
    "def scrape_article(url, keywords):\n",
    "    try:\n",
    "        resp = requests.get(url, headers=HEADERS, timeout=5)\n",
    "        resp.encoding = resp.apparent_encoding\n",
    "        soup = BeautifulSoup(resp.text, 'html.parser')\n",
    "\n",
    "        title = soup.title.text.strip() if soup.title else \"No Title\"\n",
    "        paragraphs = soup.find_all(['p', 'article'])\n",
    "        content = ' '.join([p.get_text() for p in paragraphs if p.get_text().strip()])\n",
    "\n",
    "        if any(k.lower() in content.lower() for k in keywords):\n",
    "            bullets = extract_bullet_points(content, keywords)\n",
    "            print(f\"\\nğŸ”— URL: {url}\")\n",
    "            print(f\"ğŸ“° Title: {title}\")\n",
    "            print(\"ğŸ“Œ Reasons:\")\n",
    "            for b in bullets:\n",
    "                print(b)\n",
    "        else:\n",
    "            print(f\"â­ Skipped (no keyword match): {url}\")\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Failed to scrape {url}: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # ğŸ‘‡ Input line here\n",
    "    keywords_input = input(\"ğŸ” Enter keywords (comma-separated): \")\n",
    "    keywords = [k.strip() for k in keywords_input.split(',') if k.strip()]\n",
    "    query = '+'.join(keywords + ['site:moneycontrol.com OR site:reuters.com OR site:cnbc.com OR site:livemint.com OR site:economictimes.indiatimes.com'])\n",
    "\n",
    "    print(f\"\\nğŸ” Searching Yahoo for: {query.replace('+', ' ')}\")\n",
    "    urls = yahoo_search(query)\n",
    "\n",
    "    print(f\"\\nâœ… Found {len(urls)} articles. Now filtering...\\n\")\n",
    "    for url in urls:\n",
    "        scrape_article(url, keywords)\n",
    "        time.sleep(1.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ccd1eb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” Enter keywords (comma-separated): hdfc\n",
      "\n",
      "ğŸ“¡ Scanning multiple sites for mentions of: hdfc\n",
      "\n",
      "ğŸŒ Reuters ...\n",
      "ğŸŒ CNBC ...\n",
      "ğŸŒ MarketWatch ...\n",
      "ğŸŒ Screener ...\n",
      "ğŸŒ Moneycontrol ...\n",
      "ğŸŒ Yahoo Finance ...\n",
      "ğŸŒ Economic Times ...\n",
      "ğŸŒ LiveMint ...\n",
      "\n",
      "âœ… Scraped 25 total articles. Now filtering...\n",
      "\n",
      "â­ Skipped (no keyword match): https://www.cnbc.com/2023/05/11/market-strategist-survey-forecast.html\n",
      "â­ Skipped (no keyword match): https://www.cnbc.com/2025/03/19/cnbc-pro-stock-lists-here-are-the-latest-stocks-including-all-weather-plays.html\n",
      "â­ Skipped (no keyword match): https://www.cnbc.com/2025/04/11/stocks-making-the-biggest-moves-midday-aapl-stla-blk-ulcc-and-jpm.html\n",
      "â­ Skipped (no keyword match): https://www.cnbc.com/2025/04/11/jamie-dimon-expects-sp-500-earnings-estimates-to-fall-amid-uncertainty.html\n",
      "â­ Skipped (no keyword match): https://www.cnbc.com/2025/04/11/tariffs-spell-trouble-for-vcs-amid-klarna-stubhub-ipo-delays.html\n",
      "â­ Skipped (no keyword match): https://www.moneycontrol.com/news/\n",
      "â­ Skipped (no keyword match): https://www.moneycontrol.com/news/business/\n",
      "\n",
      "ğŸ”— URL: https://www.moneycontrol.com/news/business/economy/\n",
      "ğŸ“° Title: Economy News - Latest News on Indian Economy, Government Policy   - Moneycontrol.com\n",
      "ğŸ“Œ Reasons:\n",
      "â€¢ Infosys, Wipro, HDFC Bank and ICICI Bank will release Q4 results\n",
      "â­ Skipped (no keyword match): https://www.moneycontrol.com/news/business/companies/\n",
      "â­ Skipped (no keyword match): https://www.moneycontrol.com/news/business/mutual-funds/\n",
      "â­ Skipped (no keyword match): https://www.yahoo.com/news/\n",
      "â­ Skipped (no keyword match): https://www.yahoo.com/news/us/\n",
      "â­ Skipped (no keyword match): https://www.yahoo.com/news/politics/\n",
      "â­ Skipped (no keyword match): https://www.yahoo.com/news/world/\n",
      "â­ Skipped (no keyword match): https://www.yahoo.com/news/health/\n",
      "â­ Skipped (no keyword match): https://economictimes.indiatimes.com/markets/live-coverage\n",
      "\n",
      "ğŸ”— URL: https://economictimes.indiatimes.com/markets/stocks\n",
      "ğŸ“° Title: Stock Market News, Latest Stock News - Stock Market Live Updates, Stock Market Today\n",
      "ğŸ“Œ Reasons:\n",
      "â€¢ JM Financial reiterates Buy on Info Edge (India), lowers target price to Rs 7,800 JM Financial maintains Buy on TBO Tek, lowers target price to Rs 1,400  ICICI Securities maintains Buy on Vishal Mega Mart, target price Rs 140  Buy Stylam Industries, target price Rs 2,525:  HDFC Securities  Hold Avenue Supermarts, target price Rs 3,880:  JM Financial  I-Sec initiates coverage on Adani Green with a Buy call, target price Rs 1,150 Buy Century Plyboards, target price Rs 1,005:  HDFC Securities  Pentagon fires US base chief in Greenland US envoy meets Putin for Ukraine peace talks EU's big warning over Trump tariffs Macron warns EU over Trump tariff pause US ballerina Ksenia Karelin walks free US-China spark global trade war Tamil Nadu elections: AIADMK, BJP to fight polls together Electronic voting systems vulnerable to hackers: Tulsi Gabbard Alberta Premier endorses Pierre Poilievre for Canada Elections Stop stealing Texas farmersâ€™ water, or face tariffs:Trump to Mexico EAM Jaishankar hints at Indiaâ€™s 'big deals' with USA, EU & UK US-India continue to work to combat terrorism: Tammy Bruce 'They want the Chinese Communists out': Hegseth on Panama deal Inspect before you invest\n",
      "â­ Skipped (no keyword match): https://economictimes.indiatimes.com/markets/stocks/news\n",
      "\n",
      "ğŸ”— URL: https://economictimes.indiatimes.com/markets/stocks/liveblog\n",
      "ğŸ“° Title: Live Blog - Stocks - Markets - The Economic Times\n",
      "ğŸ“Œ Reasons:\n",
      "â€¢ Strength in HDFC Bank and IT stocks was offset by losses in Reliance Industries, ICICI Bank, and M&M\n",
      "â€¢ Trump's tariff threats and declines in Reliance Industries and HDFC Bank weighed on markets, erasing early gains from softer inflation data\n",
      "â€¢ Sensex Today | Stock Market LIVE Updates | Indian benchmark indices, Sensex and Nifty, reversed early gains and turned negative on Thursday, pressured by declines in HDFC Bank, Airtel, ITC, and Infosys\n",
      "â­ Skipped (no keyword match): https://economictimes.indiatimes.com/markets/stocks/stock-liveblog\n",
      "â­ Skipped (no keyword match): https://www.livemint.com/market/market-stats\n",
      "â­ Skipped (no keyword match): https://www.livemint.com/market/mark-to-market\n",
      "â­ Skipped (no keyword match): https://www.livemint.com/market/commodities\n",
      "â­ Skipped (no keyword match): https://www.livemint.com/market/cryptocurrency\n",
      "â­ Skipped (no keyword match): https://www.livemint.com/market/ipo\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "\n",
    "HEADERS = {\"User-Agent\": \"Mozilla/5.0\"}\n",
    "\n",
    "def get_article_links(base_url, path_filter, domain):\n",
    "    try:\n",
    "        response = requests.get(base_url, headers=HEADERS, timeout=5)\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        links = []\n",
    "        for a in soup.find_all('a', href=True):\n",
    "            href = a['href']\n",
    "            if path_filter in href:\n",
    "                full_url = href if href.startswith(\"http\") else domain + href\n",
    "                if full_url not in links:\n",
    "                    links.append(full_url)\n",
    "            if len(links) >= 5:\n",
    "                break\n",
    "        return links\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Failed to fetch links from {base_url}: {e}\")\n",
    "        return []\n",
    "\n",
    "def extract_bullet_points(content, keywords):\n",
    "    bullets = []\n",
    "    sentences = content.split('.')\n",
    "    # Prioritize sentences with all keywords\n",
    "    for sentence in sentences:\n",
    "        if all(k.lower() in sentence.lower() for k in keywords):\n",
    "            bullets.append(\"â€¢ \" + sentence.strip())\n",
    "    # Fallback to any keyword\n",
    "    if not bullets:\n",
    "        for sentence in sentences:\n",
    "            if any(k.lower() in sentence.lower() for k in keywords):\n",
    "                bullets.append(\"â€¢ \" + sentence.strip())\n",
    "    return bullets[:3]\n",
    "\n",
    "def scrape_and_filter_article(url, keywords):\n",
    "    try:\n",
    "        resp = requests.get(url, headers=HEADERS, timeout=5)\n",
    "        resp.encoding = resp.apparent_encoding\n",
    "        soup = BeautifulSoup(resp.text, 'html.parser')\n",
    "\n",
    "        title = soup.title.text.strip() if soup.title else \"No Title\"\n",
    "        paragraphs = soup.find_all('p')\n",
    "        content = ' '.join([p.get_text() for p in paragraphs if p.get_text().strip()])\n",
    "\n",
    "        if any(k.lower() in content.lower() for k in keywords):\n",
    "            bullets = extract_bullet_points(content, keywords)\n",
    "            print(f\"\\nğŸ”— URL: {url}\")\n",
    "            print(f\"ğŸ“° Title: {title}\")\n",
    "            print(\"ğŸ“Œ Reasons:\")\n",
    "            for b in bullets:\n",
    "                print(b)\n",
    "        else:\n",
    "            print(f\"â­ Skipped (no keyword match): {url}\")\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Failed to scrape {url}: {e}\")\n",
    "\n",
    "# ğŸŒ Expanded list of structured & relevant market news sources\n",
    "sources = [\n",
    "    {\n",
    "        \"name\": \"Reuters\",\n",
    "        \"url\": \"https://www.reuters.com/business/\",\n",
    "        \"filter\": \"/business/\",\n",
    "        \"domain\": \"https://www.reuters.com\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"CNBC\",\n",
    "        \"url\": \"https://www.cnbc.com/finance/\",\n",
    "        \"filter\": \"/202\",\n",
    "        \"domain\": \"https://www.cnbc.com\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"MarketWatch\",\n",
    "        \"url\": \"https://www.marketwatch.com/latest-news?mod=top_nav\",\n",
    "        \"filter\": \"/story/\",\n",
    "        \"domain\": \"https://www.marketwatch.com\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Screener\",\n",
    "        \"url\": \"https://www.screener.in/news/\",\n",
    "        \"filter\": \"/news/\",\n",
    "        \"domain\": \"https://www.screener.in\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Moneycontrol\",\n",
    "        \"url\": \"https://www.moneycontrol.com/news/business/\",\n",
    "        \"filter\": \"/news/\",\n",
    "        \"domain\": \"https://www.moneycontrol.com\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Yahoo Finance\",\n",
    "        \"url\": \"https://finance.yahoo.com/\",\n",
    "        \"filter\": \"/news/\",\n",
    "        \"domain\": \"https://finance.yahoo.com\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Economic Times\",\n",
    "        \"url\": \"https://economictimes.indiatimes.com/markets\",\n",
    "        \"filter\": \"/markets/\",\n",
    "        \"domain\": \"https://economictimes.indiatimes.com\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"LiveMint\",\n",
    "        \"url\": \"https://www.livemint.com/market\",\n",
    "        \"filter\": \"/market/\",\n",
    "        \"domain\": \"https://www.livemint.com\"\n",
    "    }\n",
    "]\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # ğŸ‘‡ğŸ‘‡ğŸ‘‡ INPUT LINE HERE ğŸ‘‡ğŸ‘‡ğŸ‘‡\n",
    "    keywords_input = input(\"ğŸ” Enter keywords (comma-separated): \")\n",
    "    keywords = [k.strip() for k in keywords_input.split(',') if k.strip()]\n",
    "\n",
    "    all_urls = []\n",
    "    print(f\"\\nğŸ“¡ Scanning multiple sites for mentions of: {', '.join(keywords)}\\n\")\n",
    "\n",
    "    for source in sources:\n",
    "        print(f\"ğŸŒ {source['name']} ...\")\n",
    "        urls = get_article_links(source['url'], source['filter'], source['domain'])\n",
    "        all_urls.extend(urls)\n",
    "        time.sleep(1)\n",
    "\n",
    "    print(f\"\\nâœ… Scraped {len(all_urls)} total articles. Now filtering...\\n\")\n",
    "    for url in all_urls:\n",
    "        scrape_and_filter_article(url, keywords)\n",
    "        time.sleep(1.5)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
