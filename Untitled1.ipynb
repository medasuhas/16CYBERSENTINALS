{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7a08750",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import re\n",
    "\n",
    "HEADERS = {\"User-Agent\": \"Mozilla/5.0\"}\n",
    "\n",
    "def yahoo_search(query, num_results=10):\n",
    "    search_url = f\"https://search.yahoo.com/search?p={query}\"\n",
    "    try:\n",
    "        response = requests.get(search_url, headers=HEADERS, timeout=5)\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        results = []\n",
    "\n",
    "        for a in soup.select(\"a[href^='http']\"):\n",
    "            href = a['href']\n",
    "            if any(domain in href for domain in ['moneycontrol.com', 'reuters.com', 'livemint.com', 'cnbc.com', 'economictimes.indiatimes.com']):\n",
    "                if href not in results:\n",
    "                    results.append(href)\n",
    "            if len(results) >= num_results:\n",
    "                break\n",
    "        return results\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Yahoo Search failed: {e}\")\n",
    "        return []\n",
    "\n",
    "def extract_bullet_points(content, keywords):\n",
    "    bullets = []\n",
    "    sentences = re.split(r'\\.|\\?|!', content)\n",
    "    for sentence in sentences:\n",
    "        if all(k.lower() in sentence.lower() for k in keywords):\n",
    "            bullets.append(\"‚Ä¢ \" + sentence.strip())\n",
    "    if not bullets:\n",
    "        for sentence in sentences:\n",
    "            if any(k.lower() in sentence.lower() for k in keywords):\n",
    "                bullets.append(\"‚Ä¢ \" + sentence.strip())\n",
    "    return bullets[:3]\n",
    "\n",
    "def scrape_article(url, keywords):\n",
    "    try:\n",
    "        resp = requests.get(url, headers=HEADERS, timeout=5)\n",
    "        resp.encoding = resp.apparent_encoding\n",
    "        soup = BeautifulSoup(resp.text, 'html.parser')\n",
    "\n",
    "        title = soup.title.text.strip() if soup.title else \"No Title\"\n",
    "        paragraphs = soup.find_all(['p', 'article'])\n",
    "        content = ' '.join([p.get_text() for p in paragraphs if p.get_text().strip()])\n",
    "\n",
    "        if any(k.lower() in content.lower() for k in keywords):\n",
    "            bullets = extract_bullet_points(content, keywords)\n",
    "            print(f\"\\nüîó URL: {url}\")\n",
    "            print(f\"üì∞ Title: {title}\")\n",
    "            print(\"üìå Reasons:\")\n",
    "            for b in bullets:\n",
    "                print(b)\n",
    "        else:\n",
    "            print(f\"‚è≠ Skipped (no keyword match): {url}\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Failed to scrape {url}: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # üëá Input line here\n",
    "    keywords_input = input(\"üîç Enter keywords (comma-separated): \")\n",
    "    keywords = [k.strip() for k in keywords_input.split(',') if k.strip()]\n",
    "    query = '+'.join(keywords + ['site:moneycontrol.com OR site:reuters.com OR site:cnbc.com OR site:livemint.com OR site:economictimes.indiatimes.com'])\n",
    "\n",
    "    print(f\"\\nüîé Searching Yahoo for: {query.replace('+', ' ')}\")\n",
    "    urls = yahoo_search(query)\n",
    "\n",
    "    print(f\"\\n‚úÖ Found {len(urls)} articles. Now filtering...\\n\")\n",
    "    for url in urls:\n",
    "        scrape_article(url, keywords)\n",
    "        time.sleep(1.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ccd1eb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Enter keywords (comma-separated): hdfc\n",
      "\n",
      "üì° Scanning multiple sites for mentions of: hdfc\n",
      "\n",
      "üåê Reuters ...\n",
      "üåê CNBC ...\n",
      "üåê MarketWatch ...\n",
      "üåê Screener ...\n",
      "üåê Moneycontrol ...\n",
      "üåê Yahoo Finance ...\n",
      "üåê Economic Times ...\n",
      "üåê LiveMint ...\n",
      "\n",
      "‚úÖ Scraped 25 total articles. Now filtering...\n",
      "\n",
      "‚è≠ Skipped (no keyword match): https://www.cnbc.com/2023/05/11/market-strategist-survey-forecast.html\n",
      "‚è≠ Skipped (no keyword match): https://www.cnbc.com/2025/03/19/cnbc-pro-stock-lists-here-are-the-latest-stocks-including-all-weather-plays.html\n",
      "‚è≠ Skipped (no keyword match): https://www.cnbc.com/2025/04/11/stocks-making-the-biggest-moves-midday-aapl-stla-blk-ulcc-and-jpm.html\n",
      "‚è≠ Skipped (no keyword match): https://www.cnbc.com/2025/04/11/jamie-dimon-expects-sp-500-earnings-estimates-to-fall-amid-uncertainty.html\n",
      "‚è≠ Skipped (no keyword match): https://www.cnbc.com/2025/04/11/tariffs-spell-trouble-for-vcs-amid-klarna-stubhub-ipo-delays.html\n",
      "‚è≠ Skipped (no keyword match): https://www.moneycontrol.com/news/\n",
      "‚è≠ Skipped (no keyword match): https://www.moneycontrol.com/news/business/\n",
      "\n",
      "üîó URL: https://www.moneycontrol.com/news/business/economy/\n",
      "üì∞ Title: Economy News - Latest News on Indian Economy, Government Policy   - Moneycontrol.com\n",
      "üìå Reasons:\n",
      "‚Ä¢ Infosys, Wipro, HDFC Bank and ICICI Bank will release Q4 results\n",
      "‚è≠ Skipped (no keyword match): https://www.moneycontrol.com/news/business/companies/\n",
      "‚è≠ Skipped (no keyword match): https://www.moneycontrol.com/news/business/mutual-funds/\n",
      "‚è≠ Skipped (no keyword match): https://www.yahoo.com/news/\n",
      "‚è≠ Skipped (no keyword match): https://www.yahoo.com/news/us/\n",
      "‚è≠ Skipped (no keyword match): https://www.yahoo.com/news/politics/\n",
      "‚è≠ Skipped (no keyword match): https://www.yahoo.com/news/world/\n",
      "‚è≠ Skipped (no keyword match): https://www.yahoo.com/news/health/\n",
      "‚è≠ Skipped (no keyword match): https://economictimes.indiatimes.com/markets/live-coverage\n",
      "\n",
      "üîó URL: https://economictimes.indiatimes.com/markets/stocks\n",
      "üì∞ Title: Stock Market News, Latest Stock News - Stock Market Live Updates, Stock Market Today\n",
      "üìå Reasons:\n",
      "‚Ä¢ JM Financial reiterates Buy on Info Edge (India), lowers target price to Rs 7,800 JM Financial maintains Buy on TBO Tek, lowers target price to Rs 1,400  ICICI Securities maintains Buy on Vishal Mega Mart, target price Rs 140  Buy Stylam Industries, target price Rs 2,525:  HDFC Securities  Hold Avenue Supermarts, target price Rs 3,880:  JM Financial  I-Sec initiates coverage on Adani Green with a Buy call, target price Rs 1,150 Buy Century Plyboards, target price Rs 1,005:  HDFC Securities  Pentagon fires US base chief in Greenland US envoy meets Putin for Ukraine peace talks EU's big warning over Trump tariffs Macron warns EU over Trump tariff pause US ballerina Ksenia Karelin walks free US-China spark global trade war Tamil Nadu elections: AIADMK, BJP to fight polls together Electronic voting systems vulnerable to hackers: Tulsi Gabbard Alberta Premier endorses Pierre Poilievre for Canada Elections Stop stealing Texas farmers‚Äô water, or face tariffs:Trump to Mexico EAM Jaishankar hints at India‚Äôs 'big deals' with USA, EU & UK US-India continue to work to combat terrorism: Tammy Bruce 'They want the Chinese Communists out': Hegseth on Panama deal Inspect before you invest\n",
      "‚è≠ Skipped (no keyword match): https://economictimes.indiatimes.com/markets/stocks/news\n",
      "\n",
      "üîó URL: https://economictimes.indiatimes.com/markets/stocks/liveblog\n",
      "üì∞ Title: Live Blog - Stocks - Markets - The Economic Times\n",
      "üìå Reasons:\n",
      "‚Ä¢ Strength in HDFC Bank and IT stocks was offset by losses in Reliance Industries, ICICI Bank, and M&M\n",
      "‚Ä¢ Trump's tariff threats and declines in Reliance Industries and HDFC Bank weighed on markets, erasing early gains from softer inflation data\n",
      "‚Ä¢ Sensex Today | Stock Market LIVE Updates | Indian benchmark indices, Sensex and Nifty, reversed early gains and turned negative on Thursday, pressured by declines in HDFC Bank, Airtel, ITC, and Infosys\n",
      "‚è≠ Skipped (no keyword match): https://economictimes.indiatimes.com/markets/stocks/stock-liveblog\n",
      "‚è≠ Skipped (no keyword match): https://www.livemint.com/market/market-stats\n",
      "‚è≠ Skipped (no keyword match): https://www.livemint.com/market/mark-to-market\n",
      "‚è≠ Skipped (no keyword match): https://www.livemint.com/market/commodities\n",
      "‚è≠ Skipped (no keyword match): https://www.livemint.com/market/cryptocurrency\n",
      "‚è≠ Skipped (no keyword match): https://www.livemint.com/market/ipo\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "\n",
    "HEADERS = {\"User-Agent\": \"Mozilla/5.0\"}\n",
    "\n",
    "def get_article_links(base_url, path_filter, domain):\n",
    "    try:\n",
    "        response = requests.get(base_url, headers=HEADERS, timeout=5)\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        links = []\n",
    "        for a in soup.find_all('a', href=True):\n",
    "            href = a['href']\n",
    "            if path_filter in href:\n",
    "                full_url = href if href.startswith(\"http\") else domain + href\n",
    "                if full_url not in links:\n",
    "                    links.append(full_url)\n",
    "            if len(links) >= 5:\n",
    "                break\n",
    "        return links\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Failed to fetch links from {base_url}: {e}\")\n",
    "        return []\n",
    "\n",
    "def extract_bullet_points(content, keywords):\n",
    "    bullets = []\n",
    "    sentences = content.split('.')\n",
    "    # Prioritize sentences with all keywords\n",
    "    for sentence in sentences:\n",
    "        if all(k.lower() in sentence.lower() for k in keywords):\n",
    "            bullets.append(\"‚Ä¢ \" + sentence.strip())\n",
    "    # Fallback to any keyword\n",
    "    if not bullets:\n",
    "        for sentence in sentences:\n",
    "            if any(k.lower() in sentence.lower() for k in keywords):\n",
    "                bullets.append(\"‚Ä¢ \" + sentence.strip())\n",
    "    return bullets[:3]\n",
    "\n",
    "def scrape_and_filter_article(url, keywords):\n",
    "    try:\n",
    "        resp = requests.get(url, headers=HEADERS, timeout=5)\n",
    "        resp.encoding = resp.apparent_encoding\n",
    "        soup = BeautifulSoup(resp.text, 'html.parser')\n",
    "\n",
    "        title = soup.title.text.strip() if soup.title else \"No Title\"\n",
    "        paragraphs = soup.find_all('p')\n",
    "        content = ' '.join([p.get_text() for p in paragraphs if p.get_text().strip()])\n",
    "\n",
    "        if any(k.lower() in content.lower() for k in keywords):\n",
    "            bullets = extract_bullet_points(content, keywords)\n",
    "            print(f\"\\nüîó URL: {url}\")\n",
    "            print(f\"üì∞ Title: {title}\")\n",
    "            print(\"üìå Reasons:\")\n",
    "            for b in bullets:\n",
    "                print(b)\n",
    "        else:\n",
    "            print(f\"‚è≠ Skipped (no keyword match): {url}\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Failed to scrape {url}: {e}\")\n",
    "\n",
    "# üåê Expanded list of structured & relevant market news sources\n",
    "sources = [\n",
    "    {\n",
    "        \"name\": \"Reuters\",\n",
    "        \"url\": \"https://www.reuters.com/business/\",\n",
    "        \"filter\": \"/business/\",\n",
    "        \"domain\": \"https://www.reuters.com\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"CNBC\",\n",
    "        \"url\": \"https://www.cnbc.com/finance/\",\n",
    "        \"filter\": \"/202\",\n",
    "        \"domain\": \"https://www.cnbc.com\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"MarketWatch\",\n",
    "        \"url\": \"https://www.marketwatch.com/latest-news?mod=top_nav\",\n",
    "        \"filter\": \"/story/\",\n",
    "        \"domain\": \"https://www.marketwatch.com\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Screener\",\n",
    "        \"url\": \"https://www.screener.in/news/\",\n",
    "        \"filter\": \"/news/\",\n",
    "        \"domain\": \"https://www.screener.in\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Moneycontrol\",\n",
    "        \"url\": \"https://www.moneycontrol.com/news/business/\",\n",
    "        \"filter\": \"/news/\",\n",
    "        \"domain\": \"https://www.moneycontrol.com\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Yahoo Finance\",\n",
    "        \"url\": \"https://finance.yahoo.com/\",\n",
    "        \"filter\": \"/news/\",\n",
    "        \"domain\": \"https://finance.yahoo.com\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Economic Times\",\n",
    "        \"url\": \"https://economictimes.indiatimes.com/markets\",\n",
    "        \"filter\": \"/markets/\",\n",
    "        \"domain\": \"https://economictimes.indiatimes.com\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"LiveMint\",\n",
    "        \"url\": \"https://www.livemint.com/market\",\n",
    "        \"filter\": \"/market/\",\n",
    "        \"domain\": \"https://www.livemint.com\"\n",
    "    }\n",
    "]\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # üëáüëáüëá INPUT LINE HERE üëáüëáüëá\n",
    "    keywords_input = input(\"üîç Enter keywords (comma-separated): \")\n",
    "    keywords = [k.strip() for k in keywords_input.split(',') if k.strip()]\n",
    "\n",
    "    all_urls = []\n",
    "    print(f\"\\nüì° Scanning multiple sites for mentions of: {', '.join(keywords)}\\n\")\n",
    "\n",
    "    for source in sources:\n",
    "        print(f\"üåê {source['name']} ...\")\n",
    "        urls = get_article_links(source['url'], source['filter'], source['domain'])\n",
    "        all_urls.extend(urls)\n",
    "        time.sleep(1)\n",
    "\n",
    "    print(f\"\\n‚úÖ Scraped {len(all_urls)} total articles. Now filtering...\\n\")\n",
    "    for url in all_urls:\n",
    "        scrape_and_filter_article(url, keywords)\n",
    "        time.sleep(1.5)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
